{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.plotting import plot_time, plot_sep, plot_trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"income\"\n",
    "STATE = \"OK\"\n",
    "DATASET = TASK + \"_\" + STATE\n",
    "DATASET = TASK + \"_\" + STATE\n",
    "loaded_models = []\n",
    "\n",
    "experiments_to_read = {\n",
    "    'SGD': {\n",
    "        'unconstrained': 0.05\n",
    "    },\n",
    "    'SSG': {\n",
    "        \"loss_equality\": 0.005\n",
    "    },\n",
    "    'SSLALM': {\n",
    "        \"loss_equality\": 0.005\n",
    "    },\n",
    "    'StochasticGhost': {\n",
    "        'loss_equality': 0.005\n",
    "    },\n",
    "    'TorchSSG': {\n",
    "        # \"abs_max_dev_from_overall_tpr\": 0.03,\n",
    "        # \"abs_diff_pr\": 0.05\n",
    "    },\n",
    "    'TorchSSLALM': {\n",
    "        # \"abs_max_dev_from_overall_tpr\": 0.03,\n",
    "        # \"abs_diff_pr\": 0.05\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import os\n",
    "\n",
    "# names = product(alg_list, constr_list, lb_list)\n",
    "alg_states = {}\n",
    "full_eval_train = {}\n",
    "full_eval_test = {}\n",
    "\n",
    "for alg, con in experiments_to_read.items():\n",
    "    for constraint, bound in con.items():\n",
    "        FILE_EXT = \".pt\"\n",
    "        dir = f\"./utils/exp_results/{constraint}\"\n",
    "\n",
    "        filename_state = os.path.join(dir, f\"{alg}_\" + f\"{DATASET}_{bound}.csv\")\n",
    "        filename_full_train = os.path.join(dir, f\"AFTER_{alg}_\" + f\"{DATASET}_{bound}_train.csv\")\n",
    "        filename_full_test = os.path.join(dir, f\"AFTER_{alg}_\" + f\"{DATASET}_{bound}_test.csv\")\n",
    "        try:\n",
    "            data_state = pd.read_pickle(filename_state).reset_index()\n",
    "            data_full_train = pd.read_pickle(filename_full_train).reset_index()\n",
    "            data_full_test = pd.read_pickle(filename_full_test).reset_index()\n",
    "\n",
    "            alg_states['__'.join([alg, constraint, str(bound)])] = data_state\n",
    "            full_eval_train['__'.join([alg, constraint, str(bound)])] = data_full_train\n",
    "            full_eval_test['__'.join([alg, constraint, str(bound)])] = data_full_test\n",
    "\n",
    "            print(f'loaded {alg} | {constraint} | {bound}')\n",
    "        except FileNotFoundError: \n",
    "            print(f'not found {alg} | {constraint} | {bound} at {dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def explode_column(df, col, names, m):\n",
    "    df[names] = list(\n",
    "        df[col].map(\n",
    "                    lambda x: [np.nan]*m if np.all(np.isnan(x)) else x \n",
    "                    )\n",
    "        )\n",
    "\n",
    "def aggregate_stats(live_stats, after_stats, constraint_bound):\n",
    "    \"\"\"\n",
    "    live_stats: states of the algorithm evaluated during run\n",
    "    after_stats: statistics evaluated on full set after run\n",
    "    \"\"\"\n",
    "    live_stats.columns = live_stats.columns.map(lambda x: str(x) + '_live' if x == 'c' else x)\n",
    "    after_stats.columns = after_stats.columns.map(lambda x: str(x) + '_full' if x == 'c' else x)\n",
    "    # combine into one dataframe\n",
    "    stats_joined = after_stats.set_index(['iteration', 'trial']).join(live_stats.set_index(['iteration', 'trial']), on=['iteration', 'trial'], how='inner',lsuffix='_full', rsuffix='_live')\n",
    "    for col in stats_joined.columns:\n",
    "        if col == \"time\":\n",
    "            continue\n",
    "        # change [list] into list\n",
    "        if isinstance(stats_joined[col].iloc[0], list):\n",
    "            stats_joined[col] = stats_joined[col].map(lambda x: x[0] if not np.all(np.isnan(x)) else x)\n",
    "        # \"explode\" ndarray column into separate columns\n",
    "        if isinstance(stats_joined[col].iloc[0], np.ndarray):\n",
    "            if len(stats_joined[col].iloc[0].shape) == 1 and col in ['c_live', 'c_full']:\n",
    "                m = len(stats_joined[col].iloc[0])\n",
    "            \n",
    "                explode_column(stats_joined, col, [f'{col}{i}' for i in range(m)], m)\n",
    "                for i in range(m):\n",
    "                    stats_joined[f'{col}{i}_corrected'] = stats_joined[f'{col}{i}'] + constraint_bound\n",
    "\n",
    "            # add norm for ndarray columns\n",
    "            stats_joined[f'{col}_norm'] = stats_joined.apply(lambda x: np.linalg.norm(x[col]),axis=1)\n",
    "\n",
    "    stats_joined.dropna(axis=0, how='all', inplace=True, subset=[x for x in stats_joined.columns if x not in ['cb', 'time', 'constraint_name']])\n",
    "\n",
    "    # convert one-element ndarrays into floats\n",
    "    for col in stats_joined.columns:\n",
    "        if isinstance(stats_joined[col].iloc[0], np.ndarray):\n",
    "            if stats_joined[col].iloc[0].ndim == 0 or stats_joined[col].iloc[0].ndim == 1 and stats_joined[col].iloc[0].shape[0] == 1:\n",
    "                stats_joined[col] = stats_joined[col].astype(float)\n",
    "\n",
    "    stats_joined.reset_index(drop=False, inplace=True)\n",
    "\n",
    "    return stats_joined\n",
    "\n",
    "\n",
    "data_train = {}\n",
    "data_test = {}\n",
    "\n",
    "for name in full_eval_train.keys():\n",
    "    print(name)\n",
    "    data_train[name] = aggregate_stats(alg_states[name][['f', 'c', 'time','iteration','trial']], full_eval_train[name][['f', 'c','iteration','trial']], float(name.split('__')[-1]))\n",
    "    data_test[name] = aggregate_stats(alg_states[name][['f', 'c', 'time','iteration','trial']], full_eval_test[name][['f', 'c','iteration','trial']], float(name.split('__')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "**Plot w.r.t. time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import plot_time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# alg_name = \"TorchSSLALM\"\n",
    "# c = \"abs_diff_pr\"\n",
    "alg_name = \"SSLALM\"\n",
    "c = \"loss_equality\"\n",
    "cb = 0.005\n",
    "alg = f\"{alg_name}__{c}__{cb}\"\n",
    "\n",
    "data = data_train[alg]\n",
    "\n",
    "fl = plot_time(\n",
    "    data,\n",
    "    cb,\n",
    "    loss_col='f_full',\n",
    "    c_col='c_full0_corrected',\n",
    "    two_sided=True,\n",
    "    round_step=0.07,\n",
    "    f_ylim=(0.35, 0.77),\n",
    "    c_ylim=(-0.2, 0.2),\n",
    "    sep_figs=False,\n",
    "    add_lb=False,\n",
    "    q1=0.25,\n",
    "    q2=0.75,\n",
    "    plot_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot trajectories of each run w.r.t. iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['Mar', 'Wid', 'Div', 'Sep', 'Nev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import plot_sep, groupby_time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# alg_name = \"TorchSSG\"\n",
    "# c = \"abs_diff_pr\"\n",
    "alg_name = \"SGD\"\n",
    "c = \"unconstrained\"\n",
    "\n",
    "colors1 = plt.cm.cividis(np.linspace(0,1, 5))\n",
    "colors2 = plt.cm.viridis(np.linspace(0, 1, 5))\n",
    "colors3 = plt.cm.magma(np.linspace(0, 1, 5))\n",
    "\n",
    "colors = [colors1, colors2, colors3]\n",
    "\n",
    "f, ax = plt.subplots(3,6)\n",
    "for n, (alg_name, c) in enumerate([\n",
    "    ('SGD','unconstrained'),\n",
    "    ('TorchSSLALM','abs_diff_pr'),\n",
    "    ('TorchSSG','abs_diff_pr')\n",
    "    ]):\n",
    "\n",
    "    alg = f\"{alg_name}__{c}__{cb}\"\n",
    "    data = data_train[alg]\n",
    "    if 'time_r' not in data.columns:\n",
    "        _ = groupby_time(\n",
    "            data = data,\n",
    "            round_step=0.01)\n",
    "        # data['time_r'] = df['time_r'].mean().to_numpy()\n",
    "    print(alg)\n",
    "        \n",
    "\n",
    "    cb = 0.05\n",
    "    if isinstance(ax, plt.Axes):\n",
    "        ax = [ax]\n",
    "    # ax_f = plot_sep(data, plot_col='f_full', idx_col='trial')\n",
    "    # ax_f.axes[0].set_ylim(0.4,0.72)\n",
    "    # ax_f.set_figwidth(20)\n",
    "    for i in range(6):\n",
    "        ax = f.axes[i\n",
    "                    +6*n\n",
    "                    ]\n",
    "        if i == 0:\n",
    "            plot_sep(data, plot_col='f_full', x_col='time_r', idx_col='trial', ax=ax)#, colors=colors[n])\n",
    "        else:\n",
    "            plot_sep(data, plot_col=f'c_full{i-1}_corrected', x_col='time_r', idx_col='trial', ax=ax)#, colors=colors[n])\n",
    "        # ax.set_xticklabels(labels=np.arange())\n",
    "        ax.set_xticks(np.arange(0, 70, 10))\n",
    "    f.set_figwidth(30)\n",
    "    f.set_figheight(15)\n",
    "    # f.suptitle(alg_name)\n",
    "    for i in range(6):\n",
    "        ax = f.axes[i\n",
    "                    +6*n\n",
    "                    ]\n",
    "        if i == 0:\n",
    "            ax.set_ylim(0.4,0.72)\n",
    "            ax.patch.set_linewidth(2)\n",
    "            ax.patch.set_edgecolor('black')\n",
    "            if n == 0:\n",
    "                ax.set_title('Loss')\n",
    "        else:\n",
    "            ax.hlines((0, cb), 0, ax.get_xbound()[1], ls='--', color='black')\n",
    "            ax.set_ylim((-0.01, 0.01*30))\n",
    "            if n == 0:\n",
    "                ax.set_title(f'Constraint: {group_names[i-1]}')\n",
    "            else:\n",
    "                ax.tick_params(bottom=False)\n",
    "\n",
    "            \n",
    "# for n, (alg_name, c) in enumerate([\n",
    "#     ('SGD','unconstrained'),\n",
    "#     ('TorchSSLALM','abs_diff_pr'),\n",
    "#     ('TorchSSG','abs_diff_pr')\n",
    "#     ]):\n",
    "\n",
    "#     alg = f\"{alg_name}__{c}__{cb}\"\n",
    "#     data = data_test[alg]\n",
    "#     if 'time_r' not in data.columns:\n",
    "#         _ = groupby_time(\n",
    "#             data = data,\n",
    "#             round_step=0.01)\n",
    "#     cb = 0.05\n",
    "#     if isinstance(ax, plt.Axes):\n",
    "#         ax = [ax]\n",
    "#     for i in range(6):\n",
    "#         ax = f.axes[i+6*n]\n",
    "#         if i == 0:\n",
    "#             plot_sep(data, plot_col='f_full', x_col='time_r', idx_col='trial', ax=ax, alpha=0.5)\n",
    "#         else:\n",
    "#             plot_sep(data, plot_col=f'c_full{i-1}_corrected', x_col='time_r', idx_col='trial', ax=ax, alpha=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hc-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
