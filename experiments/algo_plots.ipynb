{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.plotting import plot_time, plot_sep, plot_trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"income\"\n",
    "STATE = \"OK\"\n",
    "DATASET = TASK + \"_\" + STATE\n",
    "DATASET = TASK + \"_\" + STATE\n",
    "loaded_models = []\n",
    "\n",
    "experiments_to_read = {\n",
    "    # 'SGD': {\n",
    "    #     'unconstrained': 0.05\n",
    "    # },\n",
    "    # 'SSG': {\n",
    "    #     \"loss_equality\": 0.005\n",
    "    # },\n",
    "    'SSLALM': {\n",
    "        \"loss_equality\": 0.005,\n",
    "        \"abs_diff_pr\": 0.05\n",
    "    },\n",
    "    'StochasticGhost': {\n",
    "        'loss_equality': 0.005,\n",
    "        \"abs_diff_pr\": 0.05\n",
    "    },\n",
    "    # 'TorchSSG': {\n",
    "    #     # \"abs_max_dev_from_overall_tpr\": 0.03,\n",
    "    #     # \"abs_diff_pr\": 0.05\n",
    "    # },\n",
    "    # 'TorchSSLALM': {\n",
    "    #     'loss_equality': 0.005\n",
    "    #     # \"abs_max_dev_from_overall_tpr\": 0.03,\n",
    "    #     # \"abs_diff_pr\": 0.05\n",
    "    # },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import os\n",
    "\n",
    "# names = product(alg_list, constr_list, lb_list)\n",
    "alg_states = {}\n",
    "full_eval_train = {}\n",
    "full_eval_test = {}\n",
    "\n",
    "for alg, con in experiments_to_read.items():\n",
    "    for constraint, bound in con.items():\n",
    "        FILE_EXT = \".pt\"\n",
    "        dir = f\"./utils/exp_results/{constraint}\"\n",
    "\n",
    "        filename_state = os.path.join(dir, f\"{alg}_\" + f\"{DATASET}_{bound}.csv\")\n",
    "        filename_full_train = os.path.join(dir, f\"AFTER_{alg}_\" + f\"{DATASET}_{bound}_train.csv\")\n",
    "        filename_full_test = os.path.join(dir, f\"AFTER_{alg}_\" + f\"{DATASET}_{bound}_test.csv\")\n",
    "        try:\n",
    "            data_state = pd.read_pickle(filename_state).reset_index()\n",
    "            data_full_train = pd.read_pickle(filename_full_train).reset_index()\n",
    "            data_full_test = pd.read_pickle(filename_full_test).reset_index()\n",
    "\n",
    "            alg_states['__'.join([alg, constraint, str(bound)])] = data_state\n",
    "            full_eval_train['__'.join([alg, constraint, str(bound)])] = data_full_train\n",
    "            full_eval_test['__'.join([alg, constraint, str(bound)])] = data_full_test\n",
    "\n",
    "            print(f'loaded {alg} | {constraint} | {bound}')\n",
    "        except FileNotFoundError: \n",
    "            print(f'not found {alg} | {constraint} | {bound} at {dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def explode_column(df, col, names, m):\n",
    "    df[names] = list(\n",
    "        df[col].map(\n",
    "                    lambda x: [np.nan]*m if np.all(np.isnan(x)) else x \n",
    "                    )\n",
    "        )\n",
    "\n",
    "def aggregate_stats(live_stats, after_stats, constraint_bound):\n",
    "    \"\"\"\n",
    "    live_stats: states of the algorithm evaluated during run\n",
    "    after_stats: statistics evaluated on full set after run\n",
    "    \"\"\"\n",
    "    live_stats.columns = live_stats.columns.map(lambda x: str(x) + '_live' if x == 'c' else x)\n",
    "    after_stats.columns = after_stats.columns.map(lambda x: str(x) + '_full' if x == 'c' else x)\n",
    "    # combine into one dataframe\n",
    "    stats_joined = after_stats.set_index(['iteration', 'trial']).join(live_stats.set_index(['iteration', 'trial']), on=['iteration', 'trial'], how='inner',lsuffix='_full', rsuffix='_live')\n",
    "    for col in stats_joined.columns:\n",
    "        if col == \"time\":\n",
    "            continue\n",
    "        # change [list] into list\n",
    "        if isinstance(stats_joined[col].iloc[0], list):\n",
    "            stats_joined[col] = stats_joined[col].map(lambda x: x[0] if not np.all(np.isnan(x)) else x)\n",
    "        # \"explode\" ndarray column into separate columns\n",
    "        if isinstance(stats_joined[col].iloc[0], np.ndarray):\n",
    "            if len(stats_joined[col].iloc[0].shape) == 1 and col in ['c_live', 'c_full']:\n",
    "                m = len(stats_joined[col].iloc[0])\n",
    "            \n",
    "                explode_column(stats_joined, col, [f'{col}{i}' for i in range(m)], m)\n",
    "                for i in range(m):\n",
    "                    stats_joined[f'{col}{i}_corrected'] = stats_joined[f'{col}{i}'] + constraint_bound\n",
    "\n",
    "            # add norm for ndarray columns\n",
    "            stats_joined[f'{col}_norm'] = stats_joined.apply(lambda x: np.linalg.norm(x[col]),axis=1)\n",
    "\n",
    "    stats_joined.dropna(axis=0, how='all', inplace=True, subset=[x for x in stats_joined.columns if x not in ['cb', 'time', 'constraint_name']])\n",
    "\n",
    "    # convert one-element ndarrays into floats\n",
    "    for col in stats_joined.columns:\n",
    "        if isinstance(stats_joined[col].iloc[0], np.ndarray):\n",
    "            if stats_joined[col].iloc[0].ndim == 0 or stats_joined[col].iloc[0].ndim == 1 and stats_joined[col].iloc[0].shape[0] == 1:\n",
    "                stats_joined[col] = stats_joined[col].astype(float)\n",
    "\n",
    "    stats_joined.reset_index(drop=False, inplace=True)\n",
    "\n",
    "    return stats_joined\n",
    "\n",
    "\n",
    "data_train = {}\n",
    "data_test = {}\n",
    "\n",
    "for name in full_eval_train.keys():\n",
    "    print(name)\n",
    "    data_train[name] = aggregate_stats(alg_states[name][['f', 'c', 'time','iteration','trial']], full_eval_train[name][['f', 'c','iteration','trial']], float(name.split('__')[-1]))\n",
    "    data_test[name] = aggregate_stats(alg_states[name][['f', 'c', 'time','iteration','trial']], full_eval_test[name][['f', 'c','iteration','trial']], float(name.split('__')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import plot_sep, groupby_time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "experiments = {\n",
    "    (\"StochasticGhost\", \"abs_diff_pr\", 0.05),\n",
    "    (\"SSLALM\", \"abs_diff_pr\", 0.05)\n",
    "}\n",
    "n_constraints = 1\n",
    "\n",
    "n_rows = len(experiments)\n",
    "n_cols = n_constraints+1\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(n_rows,n_cols)\n",
    "for n, (alg_name, c, cb) in enumerate(experiments):\n",
    "\n",
    "    alg = f\"{alg_name}__{c}__{cb}\"\n",
    "    data = data_train[alg]\n",
    "    if 'time_r' not in data.columns:\n",
    "        _ = groupby_time(\n",
    "            data = data,\n",
    "            round_step=0.01)\n",
    "    print(alg)\n",
    "        \n",
    "\n",
    "    cb = 0.05\n",
    "    if isinstance(ax, plt.Axes):\n",
    "        ax = [ax]\n",
    "    for i in range(n_rows):\n",
    "        ax = f.axes[i\n",
    "                    +n_rows*n\n",
    "                    ]\n",
    "        if i == 0:\n",
    "            plot_sep(data, plot_col='f_full', x_col='time_r', idx_col='trial', ax=ax)\n",
    "        else:\n",
    "            plot_sep(data, plot_col=f'c_full{i-1}_corrected', x_col='time_r', idx_col='trial', ax=ax)\n",
    "    f.set_figwidth(30)\n",
    "    f.set_figheight(15)\n",
    "    for i in range(n_rows):\n",
    "        ax = f.axes[i\n",
    "                    +n_rows*n\n",
    "                    ]\n",
    "        if i == 0:\n",
    "            ax.set_ylim(0.4,0.72)\n",
    "            ax.patch.set_linewidth(2)\n",
    "            ax.patch.set_edgecolor('black')\n",
    "            if n == 0:\n",
    "                ax.set_title('Loss')\n",
    "        else:\n",
    "            ax.hlines((0, cb), 0, ax.get_xbound()[1], ls='--', color='black')\n",
    "            ax.set_ylim((-0.01, 0.01*30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hc-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
