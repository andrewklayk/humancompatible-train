{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.plotting import plot_time, plot_sep, plot_trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"income\"\n",
    "STATE = \"OK\"\n",
    "DATASET = TASK + \"_\" + STATE\n",
    "DATASET = TASK + \"_\" + STATE\n",
    "loaded_models = []\n",
    "\n",
    "experiments_to_read = {\n",
    "    'SGD': {\n",
    "        'unconstrained': 0.01\n",
    "    },\n",
    "    'SSG': {\n",
    "        \"loss_equality\": 0.005\n",
    "    },\n",
    "    'SSLALM': {\n",
    "        \"loss_equality\": 0.005\n",
    "    },\n",
    "    'StochasticGhost': {\n",
    "        'loss_equality': 0.005\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import os\n",
    "\n",
    "# names = product(alg_list, constr_list, lb_list)\n",
    "alg_states = {}\n",
    "full_eval_train = {}\n",
    "full_eval_test = {}\n",
    "\n",
    "for alg, con in experiments_to_read.items():\n",
    "    for constraint, bound in con.items():\n",
    "        FILE_EXT = \".pt\"\n",
    "        dir = f\"./utils/exp_results/{constraint}\"\n",
    "\n",
    "        filename_state = os.path.join(dir, f\"{alg}_\" + f\"{DATASET}_{bound}.csv\")\n",
    "        filename_full_train = os.path.join(dir, f\"AFTER_{alg}_\" + f\"{DATASET}_{bound}_train.csv\")\n",
    "        filename_full_test = os.path.join(dir, f\"AFTER_{alg}_\" + f\"{DATASET}_{bound}_test.csv\")\n",
    "        try:\n",
    "            data_state = pd.read_pickle(filename_state).reset_index()\n",
    "            data_full_train = pd.read_pickle(filename_full_train).reset_index()\n",
    "            data_full_test = pd.read_pickle(filename_full_test).reset_index()\n",
    "\n",
    "            alg_states['__'.join([alg, constraint, str(bound)])] = data_state\n",
    "            full_eval_train['__'.join([alg, constraint, str(bound)])] = data_full_train\n",
    "            full_eval_test['__'.join([alg, constraint, str(bound)])] = data_full_test\n",
    "\n",
    "            print(f'loaded {alg} | {constraint} | {bound}')\n",
    "        except FileNotFoundError: \n",
    "            print(f'not found {alg} | {constraint} | {bound} at {dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def explode_column(df, col, names, m):\n",
    "    df[names] = list(\n",
    "        df[col].map(\n",
    "                    lambda x: [np.nan]*m if np.all(np.isnan(x)) else x \n",
    "                    )\n",
    "        )\n",
    "\n",
    "def aggregate_stats(live_stats, after_stats, constraint_bound):\n",
    "    \"\"\"\n",
    "    live_stats: states of the algorithm evaluated during run\n",
    "    after_stats: statistics evaluated on full set after run\n",
    "    \"\"\"\n",
    "    live_stats.columns = live_stats.columns.map(lambda x: str(x) + '_live' if x == 'c' else x)\n",
    "    after_stats.columns = after_stats.columns.map(lambda x: str(x) + '_full' if x == 'c' else x)\n",
    "    # combine into one dataframe\n",
    "    stats_joined = after_stats.set_index(['iteration', 'trial']).join(live_stats.set_index(['iteration', 'trial']), on=['iteration', 'trial'], how='inner',lsuffix='_full', rsuffix='_live')\n",
    "    for col in stats_joined.columns:\n",
    "        # change [list] into list\n",
    "        if isinstance(stats_joined[col].iloc[0], list):\n",
    "            stats_joined[col] = stats_joined[col].map(lambda x: x[0] if not np.all(np.isnan(x)) else x)\n",
    "        # \"explode\" ndarray column into separate columns\n",
    "        if isinstance(stats_joined[col].iloc[0], np.ndarray):\n",
    "            if len(stats_joined[col].iloc[0].shape) == 1 and col in ['c_live', 'c_full']:\n",
    "                m = len(stats_joined[col].iloc[0])\n",
    "            \n",
    "                explode_column(stats_joined, col, [f'{col}{i}' for i in range(m)], m)\n",
    "                for i in range(m):\n",
    "                    stats_joined[f'{col}{i}_corrected'] = stats_joined[f'{col}{i}'] + constraint_bound\n",
    "\n",
    "            # add norm for ndarray columns\n",
    "            stats_joined[f'{col}_norm'] = stats_joined.apply(lambda x: np.linalg.norm(x[col]),axis=1)\n",
    "\n",
    "    stats_joined.dropna(axis=0, how='all', inplace=True, subset=[x for x in stats_joined.columns if x not in ['cb', 'time', 'constraint_name']])\n",
    "\n",
    "    # convert one-element ndarrays into floats\n",
    "    for col in stats_joined.columns:\n",
    "        if isinstance(stats_joined[col].iloc[0], np.ndarray):\n",
    "            if stats_joined[col].iloc[0].ndim == 0 or stats_joined[col].iloc[0].ndim == 1 and stats_joined[col].iloc[0].shape[0] == 1:\n",
    "                stats_joined[col] = stats_joined[col].astype(float)\n",
    "\n",
    "    stats_joined.reset_index(drop=False, inplace=True)\n",
    "\n",
    "    return stats_joined\n",
    "\n",
    "\n",
    "data_train = {}\n",
    "data_test = {}\n",
    "\n",
    "for name in full_eval_train.keys():\n",
    "    data_train[name] = aggregate_stats(alg_states[name], full_eval_train[name], float(name.split('__')[-1]))\n",
    "    data_test[name] = aggregate_stats(alg_states[name], full_eval_test[name], float(name.split('__')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "**Plot w.r.t. time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import plot_time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "alg_name = \"StochasticGhost\"\n",
    "c = \"loss_equality\"\n",
    "cb = 0.005\n",
    "alg = f\"{alg_name}__{c}__{cb}\"\n",
    "data = data_train[alg]\n",
    "\n",
    "fl = plot_time(\n",
    "    data,\n",
    "    cb,\n",
    "    loss_col='f_full',\n",
    "    c_col='c_full0_corrected',\n",
    "    two_sided=True,\n",
    "    round_step=0.01,\n",
    "    f_ylim=(0.35, 0.77),\n",
    "    c_ylim=(-0.2, 0.2),\n",
    "    sep_figs=False,\n",
    "    add_lb=False,\n",
    "    q1=0.25,\n",
    "    q2=0.75,\n",
    "    plot_loss=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot trajectories of each run w.r.t. iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotting import plot_sep\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "alg = f\"{alg_name}__{c}__{cb}\"\n",
    "data = data_train[alg]\n",
    "\n",
    "f, ax = plt.subplots(5,4)\n",
    "if isinstance(ax, plt.Axes):\n",
    "    ax = [ax]\n",
    "ax_f = plot_sep(data, plot_col='f_full', idx_col='trial')\n",
    "ax_f.set_figwidth(20)\n",
    "for i, ax in enumerate(f.axes):\n",
    "    try:\n",
    "        plot_sep(data, plot_col=f'c_full{i}_corrected', idx_col='trial', ax=ax)\n",
    "    except:\n",
    "        break\n",
    "f.set_figwidth(30)\n",
    "f.set_figheight(20)\n",
    "f.suptitle(alg_name)\n",
    "for a in f.axes:\n",
    "    a.hlines((-cb, cb), 0, a.get_xbound()[1])\n",
    "    a.hlines(0, 0, a.get_xbound()[1])\n",
    "    a.set_ylim((-0.01*20, 0.01*20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hc-vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
