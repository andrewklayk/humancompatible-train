{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efc20cc",
   "metadata": {},
   "source": [
    "In this notebook, we will try to integrate the **Maximum Subgroup Discrepancy** tool from `humancompatible.detect` into our **fairness-constrained training** routine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136badd1",
   "metadata": {},
   "source": [
    "**MSD** automatically detects groups (as defined by arbitrary combinations of protected attribute values) that are predicted at a higher or lower rate than their complement.\n",
    "\n",
    "Our idea is to periodically detect new biases during the model training process, and dynamically add fairness constraints based on detected discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import numpy as np\n",
    "from folktables import ACSDataSource, ACSIncome, generate_categories\n",
    "\n",
    "# load folktables data\n",
    "data_source = ACSDataSource(survey_year=\"2018\", horizon=\"1-Year\", survey=\"person\")\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "definition_df = data_source.get_definitions(download=True)\n",
    "categories = generate_categories(\n",
    "    features=ACSIncome.features, definition_df=definition_df\n",
    ")\n",
    "df_feat, df_labels, _ = ACSIncome.df_to_pandas(\n",
    "    acs_data, categories=categories, dummies=True\n",
    ")\n",
    "\n",
    "sens_feature_names = [\n",
    "    \"SCHL\",\n",
    "    \"SEX\",\n",
    "    \"RAC1P\",\n",
    "    \"AGEP\",\n",
    "]  # leave OCCP out for now cause it has 524 (!) values\n",
    "sens_col_names = [\n",
    "    col for col in df_feat.columns if col.startswith(tuple(sens_feature_names))\n",
    "]\n",
    "\n",
    "features = df_feat.drop(columns=sens_col_names).to_numpy(dtype=\"float\")\n",
    "groups = df_feat[sens_col_names].to_numpy(dtype=\"float\")\n",
    "labels = df_labels.to_numpy(dtype=\"float\")\n",
    "\n",
    "# split\n",
    "indices = np.arange(len(features))\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    groups_train,\n",
    "    groups_test,\n",
    "    indices_train,\n",
    "    indices_test,\n",
    ") = train_test_split(features, labels, groups, indices, test_size=0.2, random_state=42)\n",
    "# scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# make into a pytorch dataset, remove the sensitive attribute\n",
    "features_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "labels_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "sens_train = torch.tensor(groups_train)\n",
    "dataset_train = torch.utils.data.TensorDataset(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c4fa0",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e2bfa",
   "metadata": {},
   "source": [
    "As the constraint, we use `NormLoss` from `fairret`, which penalizes the model based on the ratio between the value of a statistic for each group and the overall value: $\\sum_{s\\in S}{|1-\\frac{f(\\theta, X_s, y_s)}{f(\\theta, X, y)}|}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5714398",
   "metadata": {},
   "source": [
    "**Every N epochs (or until the loss stops decreasing?) run MSD and add a constraint for that pair of subgroups**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ffdf8",
   "metadata": {},
   "source": [
    "To run MSD efficiently, we need to get rid of the one-hot encoding, and do some minor transformations on the data. We will use a separate DataFrame for MSD inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b8968",
   "metadata": {},
   "source": [
    "Issues: each time we add a constraint, we have to reevaluate sensitive attribute encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b1e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/anaconda3/envs/detect-train/lib/python3.11/site-packages/sklearn/preprocessing/_discretization.py:296: FutureWarning: The current default behavior, quantile_method='linear', will be changed to quantile_method='averaged_inverted_cdf' in scikit-learn version 1.9 to naturally support sample weight equivalence properties by default. Pass quantile_method='averaged_inverted_cdf' explicitly to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL_1 or more years of college credit, no degree</th>\n",
       "      <th>SCHL_12th grade - no diploma</th>\n",
       "      <th>SCHL_Associate's degree</th>\n",
       "      <th>SCHL_Bachelor's degree</th>\n",
       "      <th>SCHL_Doctorate degree</th>\n",
       "      <th>SCHL_GED or alternative credential</th>\n",
       "      <th>SCHL_Grade 1</th>\n",
       "      <th>SCHL_Grade 10</th>\n",
       "      <th>SCHL_Grade 11</th>\n",
       "      <th>SCHL_Grade 2</th>\n",
       "      <th>...</th>\n",
       "      <th>AGEP_17.0_23.0</th>\n",
       "      <th>AGEP_23.0_28.0</th>\n",
       "      <th>AGEP_28.0_32.0</th>\n",
       "      <th>AGEP_32.0_37.0</th>\n",
       "      <th>AGEP_37.0_42.0</th>\n",
       "      <th>AGEP_42.0_47.0</th>\n",
       "      <th>AGEP_47.0_52.0</th>\n",
       "      <th>AGEP_52.0_57.0</th>\n",
       "      <th>AGEP_57.0_63.0</th>\n",
       "      <th>AGEP_63.0_94.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82350</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23973</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92330</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115743</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82575</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156532 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SCHL_1 or more years of college credit, no degree  \\\n",
       "82350                                                True   \n",
       "23973                                               False   \n",
       "92330                                               False   \n",
       "115743                                              False   \n",
       "82575                                               False   \n",
       "...                                                   ...   \n",
       "119879                                              False   \n",
       "103694                                              False   \n",
       "131932                                              False   \n",
       "146867                                              False   \n",
       "121958                                              False   \n",
       "\n",
       "        SCHL_12th grade - no diploma  SCHL_Associate's degree  \\\n",
       "82350                          False                    False   \n",
       "23973                          False                    False   \n",
       "92330                          False                    False   \n",
       "115743                         False                    False   \n",
       "82575                          False                    False   \n",
       "...                              ...                      ...   \n",
       "119879                         False                     True   \n",
       "103694                         False                    False   \n",
       "131932                         False                    False   \n",
       "146867                         False                    False   \n",
       "121958                         False                    False   \n",
       "\n",
       "        SCHL_Bachelor's degree  SCHL_Doctorate degree  \\\n",
       "82350                    False                  False   \n",
       "23973                    False                  False   \n",
       "92330                     True                  False   \n",
       "115743                   False                  False   \n",
       "82575                    False                  False   \n",
       "...                        ...                    ...   \n",
       "119879                   False                  False   \n",
       "103694                   False                  False   \n",
       "131932                   False                  False   \n",
       "146867                   False                  False   \n",
       "121958                   False                  False   \n",
       "\n",
       "        SCHL_GED or alternative credential  SCHL_Grade 1  SCHL_Grade 10  \\\n",
       "82350                                False         False          False   \n",
       "23973                                False         False          False   \n",
       "92330                                False         False          False   \n",
       "115743                               False         False          False   \n",
       "82575                                False         False           True   \n",
       "...                                    ...           ...            ...   \n",
       "119879                               False         False          False   \n",
       "103694                               False         False          False   \n",
       "131932                               False         False          False   \n",
       "146867                               False         False          False   \n",
       "121958                               False         False          False   \n",
       "\n",
       "        SCHL_Grade 11  SCHL_Grade 2  ...  AGEP_17.0_23.0  AGEP_23.0_28.0  \\\n",
       "82350           False         False  ...            True           False   \n",
       "23973           False         False  ...           False           False   \n",
       "92330           False         False  ...           False           False   \n",
       "115743          False         False  ...           False           False   \n",
       "82575           False         False  ...           False           False   \n",
       "...               ...           ...  ...             ...             ...   \n",
       "119879          False         False  ...           False            True   \n",
       "103694          False         False  ...           False           False   \n",
       "131932          False         False  ...           False           False   \n",
       "146867          False         False  ...           False           False   \n",
       "121958          False         False  ...           False           False   \n",
       "\n",
       "        AGEP_28.0_32.0  AGEP_32.0_37.0  AGEP_37.0_42.0  AGEP_42.0_47.0  \\\n",
       "82350            False           False           False           False   \n",
       "23973            False           False            True           False   \n",
       "92330            False            True           False           False   \n",
       "115743           False           False           False           False   \n",
       "82575            False           False           False           False   \n",
       "...                ...             ...             ...             ...   \n",
       "119879           False           False           False           False   \n",
       "103694           False            True           False           False   \n",
       "131932           False           False           False           False   \n",
       "146867           False           False            True           False   \n",
       "121958           False            True           False           False   \n",
       "\n",
       "        AGEP_47.0_52.0  AGEP_52.0_57.0  AGEP_57.0_63.0  AGEP_63.0_94.0  \n",
       "82350            False           False           False           False  \n",
       "23973            False           False           False           False  \n",
       "92330            False           False           False           False  \n",
       "115743           False            True           False           False  \n",
       "82575            False            True           False           False  \n",
       "...                ...             ...             ...             ...  \n",
       "119879           False           False           False           False  \n",
       "103694           False           False           False           False  \n",
       "131932           False            True           False           False  \n",
       "146867           False           False           False           False  \n",
       "121958           False           False           False           False  \n",
       "\n",
       "[156532 rows x 45 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, KBinsDiscretizer\n",
    "\n",
    "# for MSD, we need to do a bit of additional preprocessing:\n",
    "# - add negations for binary features as a separate column (already done via categories+get_dummies)\n",
    "# - discretize continuous features\n",
    "\n",
    "df_feat_msd, df_labels, _ = ACSIncome.df_to_pandas(\n",
    "    acs_data, categories=categories, dummies=True\n",
    ")\n",
    "df_feat_msd, df_labels = (\n",
    "    df_feat_msd[sens_col_names].iloc[indices_train],\n",
    "    df_labels.iloc[indices_train],\n",
    ")\n",
    "\n",
    "cont_sens_feature_names = [\"AGEP\"]\n",
    "ds = KBinsDiscretizer(n_bins=10, encode=\"onehot-dense\")\n",
    "cont_bins = ds.fit_transform(df_feat_msd[cont_sens_feature_names])\n",
    "for fidx, cont_feature in enumerate(cont_sens_feature_names):\n",
    "    for i in range(ds.n_bins_[fidx]):\n",
    "        lb, ub = ds.bin_edges_[fidx][i], ds.bin_edges_[fidx][i + 1]\n",
    "        df_feat_msd[\"_\".join([cont_feature, str(lb), str(ub)])] = cont_bins[\n",
    "            :, i\n",
    "        ].astype(bool)\n",
    "\n",
    "df_feat_msd.drop(columns=cont_sens_feature_names, inplace=True)\n",
    "df_feat_msd = df_feat_msd.convert_dtypes(convert_boolean=True)\n",
    "\n",
    "Conjuncts_kwargs = {\"solver\": \"glpk\", \"time_limit\": 600}\n",
    "\n",
    "# cat_features = list(set(df_feat_msd.columns) - set(cont_feature_names))\n",
    "# FEATURE_PROCESSING = {\n",
    "#     \"POBP\": lambda x: int(x) // 100,  # group by continents + US\n",
    "#     \"OCCP\": lambda x: int(x) // 100,\n",
    "#     \"PUMA\": lambda x: int(x) // 100,\n",
    "#     \"POWPUMA\": lambda x: int(x) // 1000,\n",
    "# }\n",
    "# oe = OrdinalEncoder()\n",
    "# df_feat_msd[cat_features] = oe.fit_transform(df_feat_msd[cat_features])\n",
    "\n",
    "MSD_kwargs = {\n",
    "    \"n_samples\": 200,\n",
    "}\n",
    "\n",
    "df_feat_msd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e978f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairret.statistic import PositiveRate\n",
    "from fairret.loss import NormLoss\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    features_train, torch.tensor(df_feat_msd.to_numpy(dtype=bool)), labels_train\n",
    ")\n",
    "\n",
    "# we need bigger batch size to make sure that each batch contains members of each potential subgroup\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=96)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# MSD detects discrepancies in positive predictions\n",
    "statistic = PositiveRate()\n",
    "fair_criterion = NormLoss(statistic=statistic)\n",
    "fair_crit_bound = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5cb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "\n",
    "hsize1 = 32\n",
    "hsize2 = 16\n",
    "model_con = Sequential(\n",
    "    torch.nn.Linear(features_train.shape[1], hsize1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hsize1, hsize2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hsize2, 1),\n",
    ")\n",
    "\n",
    "from humancompatible.train.optim import SSLALM_Adam\n",
    "\n",
    "optimizer = SSLALM_Adam(\n",
    "    params=model_con.parameters(),\n",
    "    m=0,\n",
    "    lr=0.05,\n",
    "    dual_lr=0.05,\n",
    "    dual_bound=50,\n",
    "    rho=1.0,\n",
    "    mu=2.0,\n",
    ")\n",
    "\n",
    "# add slack variables\n",
    "slack_vars = torch.zeros(0, requires_grad=True)\n",
    "# optimizer.add_param_group(param_group={\"params\": slack_vars, \"name\": \"slack\"})\n",
    "\n",
    "epochs = 1000\n",
    "msd_interval = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8564545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1631 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.4456871747970581, constraints: [], dual: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 0.4195505678653717, constraints: [], dual: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, loss: 0.3493681848049164, constraints: [], dual: []\n",
      "Adding new rule: [\"SCHL_Bachelor's degree\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, loss: 0.46873563528060913, constraints: [[0.02995319]], dual: [2.4426827]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, loss: 0.5981041193008423, constraints: [[0.00090436]], dual: [11.135156]\n",
      "Adding new rule: ['AGEP_17.0_23.0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101, loss: 0.6369485259056091, constraints: [[0.        ]\n",
      " [0.01366439]], dual: [11.134973   1.1143476]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150, loss: 0.6178159713745117, constraints: [[0.00038175]\n",
      " [0.00100983]], dual: [12.206237   6.0645304]\n",
      "Adding new rule: ['SEX_Male', 'RAC1P_White alone']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 151, loss: 0.6163669228553772, constraints: [[0.00018188]\n",
      " [0.00054146]\n",
      " [0.00025451]], dual: [12.220855    6.108724    0.02075543]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, loss: 0.6117810606956482, constraints: [[0.00028794]\n",
      " [0.00034323]\n",
      " [0.00021217]], dual: [13.2265625   8.623331    0.70239264]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 201, loss: 0.6182326078414917, constraints: [[0.00031957]\n",
      " [0.00027968]\n",
      " [0.00012087]], dual: [13.252546    8.646427    0.71226686]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 250, loss: 0.6148971915245056, constraints: [[2.05031536e-04]\n",
      " [4.80884244e-04]\n",
      " [2.55993361e-05]], dual: [14.162274  10.552781   1.1865553]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 251, loss: 0.6191721558570862, constraints: [[1.96570381e-04]\n",
      " [9.00425332e-04]\n",
      " [1.74309051e-05]], dual: [14.178393  10.626217   1.1879902]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300, loss: 0.6103061437606812, constraints: [[1.14646702e-04]\n",
      " [7.34636858e-04]\n",
      " [3.26486178e-05]], dual: [14.881484  12.41226    1.4319855]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 301, loss: 0.6113454699516296, constraints: [[2.43223386e-04]\n",
      " [1.40388782e-04]\n",
      " [8.17946391e-05]], dual: [14.901716  12.423829   1.4386395]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# primal eval and update\u001b[39;00m\n\u001b[32m     39\u001b[39m loss = criterion(out, batch_label)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m optimizer.step()\n\u001b[32m     42\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detect-train/lib/python3.11/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detect-train/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detect-train/lib/python3.11/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from humancompatible.detect import detect_and_score\n",
    "from humancompatible.detect.helpers import report_subgroup_bias\n",
    "from humancompatible.detect.methods.msd import get_conjuncts_MSD\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "constraints = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # clear epoch stats\n",
    "    loss_log = []\n",
    "    c_log = []\n",
    "    duals_log = []\n",
    "\n",
    "    for batch_input, batch_sens, batch_label in tqdm(dataloader, leave=False):\n",
    "        # calculate constraints and constraint grads\n",
    "        out = model_con(batch_input)\n",
    "        c_log.append([])\n",
    "        for j, conj_indices in enumerate(constraints):\n",
    "            # one-hot evaluation of rule `j`\n",
    "            sens_attrs = batch_sens[:, conj_indices]\n",
    "            rule_eval = torch.prod(sens_attrs, dim=1, keepdim=True, dtype=bool)\n",
    "            batch_rule_groups = torch.cat([rule_eval, ~rule_eval], dim=1)\n",
    "            # evaluate fairret loss\n",
    "            fair_loss = fair_criterion(out, batch_rule_groups)\n",
    "            fair_constraint = torch.max(fair_loss - fair_crit_bound, torch.zeros(1))\n",
    "            fair_constraint.backward(retain_graph=True)\n",
    "            # dual update\n",
    "            optimizer.dual_step(j, c_val=fair_constraint)\n",
    "            optimizer.zero_grad()\n",
    "            c_log[-1].append([fair_constraint.detach().item()])\n",
    "        duals_log.append(optimizer._dual_vars.detach())\n",
    "\n",
    "        # primal eval and update\n",
    "        loss = criterion(out, batch_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_log.append(loss.detach().numpy())\n",
    "        # slack variables must be non-negative. this is the \"projection\" step from the SSL-ALM paper\n",
    "        with torch.no_grad():\n",
    "            for s in slack_vars:\n",
    "                if s < 0:\n",
    "                    s.zero_()\n",
    "\n",
    "    # dimin dual stepsize\n",
    "    # optimizer.dual_lr *= 0.98\n",
    "\n",
    "    # print epoch stats\n",
    "    if epoch % msd_interval // 2 == 0:\n",
    "        print(\n",
    "            f\"Epoch: {epoch}, \"\n",
    "            f\"loss: {np.mean(loss_log)}, \"\n",
    "            f\"constraints: {np.mean(c_log, axis=0)}, \"\n",
    "            f\"dual: {np.mean(duals_log, axis=0)}\"\n",
    "        )\n",
    "\n",
    "    if (\n",
    "        epoch > 0\n",
    "        and epoch % ((1 + len(constraints)) * msd_interval) == 0\n",
    "        and len(constraints) <= 5\n",
    "    ):\n",
    "        ### find new MSD ###\n",
    "        with torch.no_grad():\n",
    "            indices = random.sample(range(len(df_feat_msd)), MSD_kwargs[\"n_samples\"])\n",
    "            MSD_sample_model_input = dataset[indices][0]\n",
    "            MSD_sample_x = df_feat_msd.iloc[indices].to_numpy(dtype=bool)\n",
    "            # get binary predictions on sample\n",
    "            MSD_sample_y = (\n",
    "                torch.nn.functional.sigmoid(model_con(MSD_sample_model_input)).squeeze()\n",
    "                > 0.5\n",
    "            ).numpy()\n",
    "        if not np.any(MSD_sample_y):\n",
    "            continue\n",
    "        conj_indices = get_conjuncts_MSD(MSD_sample_x, MSD_sample_y, **Conjuncts_kwargs)\n",
    "        print(f\"Adding new rule: {df_feat_msd.columns[conj_indices].to_list()}\")\n",
    "        constraints.append(conj_indices)\n",
    "        optimizer.add_constraint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed41e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sens[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from humancompatible.detect.binarizer import Bin\n",
    "\n",
    "\n",
    "def rule_to_indicator(rule, features):\n",
    "    \"\"\"\n",
    "    Given a rule and a tensor of one-hot variables, creates a new indicator column denoting the rule.\n",
    "    `features`must have shape (`batch_size`,`n_features`)\n",
    "    \"\"\"\n",
    "    for feature_idx, bin in rule:\n",
    "        features[feature_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579678d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    f = model_con.forward(dataset[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de6e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6255, dtype=torch.float16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(((torch.nn.functional.sigmoid(f) > 0.5) == dataset[:][2]).to(torch.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993899e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4769, 0.4559, 0.4392, 0.4757, 0.4919, 0.5193, 0.4537, 0.4199, 0.4385,\n",
       "        0.4023, 0.3916, 0.4016, 0.4039, 0.4031, 0.4086, 0.4025, 0.4282, 0.4300,\n",
       "        0.4723, 0.5128, 0.4259, 0.4359, 0.5164, 0.4432, 0.4597, 0.4572, 0.4796,\n",
       "        0.5135, 0.4557, 0.4454, 0.4731, 0.4720, 0.4660, 0.4348, 0.4614, 0.4749],\n",
       "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairret.statistic import PositiveRate\n",
    "\n",
    "preds = torch.nn.functional.sigmoid(model_con(features_train))\n",
    "pr = PositiveRate()\n",
    "pr(preds, sens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5a57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4357, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_criterion(model_con(features_train), sens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "window_len = 5\n",
    "c_mavg = np.array(\n",
    "    [np.mean(ep_c_log[i : i + window_len]) for i in range(0, len(ep_c_log), window_len)]\n",
    ")\n",
    "plt.plot(np.array(c_mavg).flatten(), lw=0.05)\n",
    "plt.hlines(y=fair_crit_bound, xmin=0, xmax=len(c_mavg), colors=\"black\", ls=\"--\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detect-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
