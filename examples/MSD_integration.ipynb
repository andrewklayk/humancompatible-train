{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efc20cc",
   "metadata": {},
   "source": [
    "In this notebook, we will try to integrate the **Maximum Subgroup Discrepancy** tool from `humancompatible.detect` into our **fairness-constrained training** routine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136badd1",
   "metadata": {},
   "source": [
    "**MSD** automatically detects groups (as defined by arbitrary combinations of protected attribute values) that are predicted at a higher or lower rate than their complement.\n",
    "\n",
    "Our idea is to periodically detect new biases during the model training process, and dynamically add fairness constraints based on detected discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b9577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import numpy as np\n",
    "from folktables import ACSDataSource, ACSIncome, generate_categories\n",
    "\n",
    "# load folktables data\n",
    "data_source = ACSDataSource(survey_year=\"2018\", horizon=\"1-Year\", survey=\"person\")\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "definition_df = data_source.get_definitions(download=True)\n",
    "categories = generate_categories(\n",
    "    features=ACSIncome.features, definition_df=definition_df\n",
    ")\n",
    "df_feat, df_labels, _ = ACSIncome.df_to_pandas(\n",
    "    acs_data, categories=categories, dummies=True\n",
    ")\n",
    "\n",
    "sens_feature_names = [\n",
    "    \"SCHL\",\n",
    "    \"SEX\",\n",
    "    \"RAC1P\",\n",
    "    \"AGEP\",\n",
    "]  # leave OCCP out for now cause it has 524 (!) values\n",
    "sens_col_names = [\n",
    "    col for col in df_feat.columns if col.startswith(tuple(sens_feature_names))\n",
    "]\n",
    "\n",
    "features = df_feat.drop(columns=sens_col_names).to_numpy(dtype=\"float\")\n",
    "groups = df_feat[sens_col_names].to_numpy(dtype=\"float\")\n",
    "labels = df_labels.to_numpy(dtype=\"float\")\n",
    "\n",
    "# split\n",
    "indices = np.arange(len(features))\n",
    "(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    groups_train,\n",
    "    groups_test,\n",
    "    indices_train,\n",
    "    indices_test,\n",
    ") = train_test_split(features, labels, groups, indices, test_size=0.2, random_state=42)\n",
    "# scale\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# make into a pytorch dataset, remove the sensitive attribute\n",
    "features_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "labels_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "sens_train = torch.tensor(groups_train)\n",
    "dataset_train = torch.utils.data.TensorDataset(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c4fa0",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e2bfa",
   "metadata": {},
   "source": [
    "As the constraint, we use `NormLoss` from `fairret`, which penalizes the model based on the ratio between the value of a statistic for each group and the overall value: $\\sum_{s\\in S}{|1-\\frac{f(\\theta, X_s, y_s)}{f(\\theta, X, y)}|}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5714398",
   "metadata": {},
   "source": [
    "**Every N epochs (or until the loss stops decreasing?) run MSD and add a constraint for that pair of subgroups**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ffdf8",
   "metadata": {},
   "source": [
    "To run MSD efficiently, we need to get rid of the one-hot encoding, and do some minor transformations on the data. We will use a separate DataFrame for MSD inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683b8968",
   "metadata": {},
   "source": [
    "Issues: each time we add a constraint, we have to reevaluate sensitive attribute encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a41b1e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/anaconda3/envs/detect-train/lib/python3.11/site-packages/sklearn/preprocessing/_discretization.py:296: FutureWarning: The current default behavior, quantile_method='linear', will be changed to quantile_method='averaged_inverted_cdf' in scikit-learn version 1.9 to naturally support sample weight equivalence properties by default. Pass quantile_method='averaged_inverted_cdf' explicitly to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCHL_1 or more years of college credit, no degree</th>\n",
       "      <th>SCHL_12th grade - no diploma</th>\n",
       "      <th>SCHL_Associate's degree</th>\n",
       "      <th>SCHL_Bachelor's degree</th>\n",
       "      <th>SCHL_Doctorate degree</th>\n",
       "      <th>SCHL_GED or alternative credential</th>\n",
       "      <th>SCHL_Grade 1</th>\n",
       "      <th>SCHL_Grade 10</th>\n",
       "      <th>SCHL_Grade 11</th>\n",
       "      <th>SCHL_Grade 2</th>\n",
       "      <th>...</th>\n",
       "      <th>AGEP_17.0_23.0</th>\n",
       "      <th>AGEP_23.0_28.0</th>\n",
       "      <th>AGEP_28.0_32.0</th>\n",
       "      <th>AGEP_32.0_37.0</th>\n",
       "      <th>AGEP_37.0_42.0</th>\n",
       "      <th>AGEP_42.0_47.0</th>\n",
       "      <th>AGEP_47.0_52.0</th>\n",
       "      <th>AGEP_52.0_57.0</th>\n",
       "      <th>AGEP_57.0_63.0</th>\n",
       "      <th>AGEP_63.0_94.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82350</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23973</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92330</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115743</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82575</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156532 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SCHL_1 or more years of college credit, no degree  \\\n",
       "82350                                                True   \n",
       "23973                                               False   \n",
       "92330                                               False   \n",
       "115743                                              False   \n",
       "82575                                               False   \n",
       "...                                                   ...   \n",
       "119879                                              False   \n",
       "103694                                              False   \n",
       "131932                                              False   \n",
       "146867                                              False   \n",
       "121958                                              False   \n",
       "\n",
       "        SCHL_12th grade - no diploma  SCHL_Associate's degree  \\\n",
       "82350                          False                    False   \n",
       "23973                          False                    False   \n",
       "92330                          False                    False   \n",
       "115743                         False                    False   \n",
       "82575                          False                    False   \n",
       "...                              ...                      ...   \n",
       "119879                         False                     True   \n",
       "103694                         False                    False   \n",
       "131932                         False                    False   \n",
       "146867                         False                    False   \n",
       "121958                         False                    False   \n",
       "\n",
       "        SCHL_Bachelor's degree  SCHL_Doctorate degree  \\\n",
       "82350                    False                  False   \n",
       "23973                    False                  False   \n",
       "92330                     True                  False   \n",
       "115743                   False                  False   \n",
       "82575                    False                  False   \n",
       "...                        ...                    ...   \n",
       "119879                   False                  False   \n",
       "103694                   False                  False   \n",
       "131932                   False                  False   \n",
       "146867                   False                  False   \n",
       "121958                   False                  False   \n",
       "\n",
       "        SCHL_GED or alternative credential  SCHL_Grade 1  SCHL_Grade 10  \\\n",
       "82350                                False         False          False   \n",
       "23973                                False         False          False   \n",
       "92330                                False         False          False   \n",
       "115743                               False         False          False   \n",
       "82575                                False         False           True   \n",
       "...                                    ...           ...            ...   \n",
       "119879                               False         False          False   \n",
       "103694                               False         False          False   \n",
       "131932                               False         False          False   \n",
       "146867                               False         False          False   \n",
       "121958                               False         False          False   \n",
       "\n",
       "        SCHL_Grade 11  SCHL_Grade 2  ...  AGEP_17.0_23.0  AGEP_23.0_28.0  \\\n",
       "82350           False         False  ...            True           False   \n",
       "23973           False         False  ...           False           False   \n",
       "92330           False         False  ...           False           False   \n",
       "115743          False         False  ...           False           False   \n",
       "82575           False         False  ...           False           False   \n",
       "...               ...           ...  ...             ...             ...   \n",
       "119879          False         False  ...           False            True   \n",
       "103694          False         False  ...           False           False   \n",
       "131932          False         False  ...           False           False   \n",
       "146867          False         False  ...           False           False   \n",
       "121958          False         False  ...           False           False   \n",
       "\n",
       "        AGEP_28.0_32.0  AGEP_32.0_37.0  AGEP_37.0_42.0  AGEP_42.0_47.0  \\\n",
       "82350            False           False           False           False   \n",
       "23973            False           False            True           False   \n",
       "92330            False            True           False           False   \n",
       "115743           False           False           False           False   \n",
       "82575            False           False           False           False   \n",
       "...                ...             ...             ...             ...   \n",
       "119879           False           False           False           False   \n",
       "103694           False            True           False           False   \n",
       "131932           False           False           False           False   \n",
       "146867           False           False            True           False   \n",
       "121958           False            True           False           False   \n",
       "\n",
       "        AGEP_47.0_52.0  AGEP_52.0_57.0  AGEP_57.0_63.0  AGEP_63.0_94.0  \n",
       "82350            False           False           False           False  \n",
       "23973            False           False           False           False  \n",
       "92330            False           False           False           False  \n",
       "115743           False            True           False           False  \n",
       "82575            False            True           False           False  \n",
       "...                ...             ...             ...             ...  \n",
       "119879           False           False           False           False  \n",
       "103694           False           False           False           False  \n",
       "131932           False            True           False           False  \n",
       "146867           False           False           False           False  \n",
       "121958           False           False           False           False  \n",
       "\n",
       "[156532 rows x 45 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, KBinsDiscretizer\n",
    "\n",
    "# for MSD, we need to do a bit of additional preprocessing:\n",
    "# - add negations for binary features as a separate column (already done via categories+get_dummies)\n",
    "# - discretize continuous features\n",
    "\n",
    "df_feat_msd, df_labels, _ = ACSIncome.df_to_pandas(\n",
    "    acs_data, categories=categories, dummies=True\n",
    ")\n",
    "df_feat_msd, df_labels = (\n",
    "    df_feat_msd[sens_col_names].iloc[indices_train],\n",
    "    df_labels.iloc[indices_train],\n",
    ")\n",
    "\n",
    "cont_sens_feature_names = [\"AGEP\"]\n",
    "ds = KBinsDiscretizer(n_bins=10, encode=\"onehot-dense\")\n",
    "cont_bins = ds.fit_transform(df_feat_msd[cont_sens_feature_names])\n",
    "for fidx, cont_feature in enumerate(cont_sens_feature_names):\n",
    "    for i in range(ds.n_bins_[fidx]):\n",
    "        lb, ub = ds.bin_edges_[fidx][i], ds.bin_edges_[fidx][i + 1]\n",
    "        df_feat_msd[\"_\".join([cont_feature, str(lb), str(ub)])] = cont_bins[\n",
    "            :, i\n",
    "        ].astype(bool)\n",
    "\n",
    "df_feat_msd.drop(columns=cont_sens_feature_names, inplace=True)\n",
    "df_feat_msd = df_feat_msd.convert_dtypes(convert_boolean=True)\n",
    "\n",
    "Conjuncts_kwargs = {\"solver\": \"glpk\", \"time_limit\": 600}\n",
    "\n",
    "# cat_features = list(set(df_feat_msd.columns) - set(cont_feature_names))\n",
    "# FEATURE_PROCESSING = {\n",
    "#     \"POBP\": lambda x: int(x) // 100,  # group by continents + US\n",
    "#     \"OCCP\": lambda x: int(x) // 100,\n",
    "#     \"PUMA\": lambda x: int(x) // 100,\n",
    "#     \"POWPUMA\": lambda x: int(x) // 1000,\n",
    "# }\n",
    "# oe = OrdinalEncoder()\n",
    "# df_feat_msd[cat_features] = oe.fit_transform(df_feat_msd[cat_features])\n",
    "\n",
    "MSD_kwargs = {\n",
    "    \"n_samples\": 800,\n",
    "}\n",
    "\n",
    "df_feat_msd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e978f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairret.statistic import PositiveRate\n",
    "from fairret.loss import NormLoss\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    features_train, torch.tensor(df_feat_msd.to_numpy(dtype=bool)), labels_train\n",
    ")\n",
    "\n",
    "# we need bigger batch size to make sure that each batch contains members of each potential subgroup\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True, batch_size=128)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# MSD detects discrepancies in positive predictions\n",
    "statistic = PositiveRate()\n",
    "fair_criterion = NormLoss(statistic=statistic)\n",
    "fair_crit_bound = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f5cb8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "\n",
    "hsize1 = 32\n",
    "hsize2 = 16\n",
    "model_con = Sequential(\n",
    "    torch.nn.Linear(features_train.shape[1], hsize1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hsize1, hsize2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hsize2, 1),\n",
    ")\n",
    "\n",
    "from torch.optim import Adam\n",
    "from humancompatible.train.dual_optim import ALM\n",
    "\n",
    "optimizer = Adam(model_con.parameters())\n",
    "dual = ALM(m=1, momentum=0.2, dampening=0.2)\n",
    "\n",
    "# add slack variables\n",
    "slack_vars = torch.zeros(10, requires_grad=True)\n",
    "optimizer.add_param_group(param_group={\"params\": slack_vars, \"name\": \"slack\"})\n",
    "\n",
    "epochs = 100\n",
    "msd_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8564545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding new rule: [\"SCHL_Associate's degree\", 'SEX_Male']\n",
      "Epoch: 0, loss: 0.46826639771461487, constraints: [[0.2205522]], dual: [0.22095282]\n",
      "Epoch: 1, loss: 0.46371814608573914, constraints: [[0.20312997]], dual: [0.43269038]\n",
      "Epoch: 2, loss: 0.45843788981437683, constraints: [[0.20374881]], dual: [0.43759423]\n",
      "Epoch: 3, loss: 0.4517832100391388, constraints: [[0.19789998]], dual: [0.42269498]\n",
      "Epoch: 4, loss: 0.45692679286003113, constraints: [[0.19773155]], dual: [0.44203988]\n",
      "Epoch: 5, loss: 0.45174553990364075, constraints: [[0.20164972]], dual: [0.42802367]\n",
      "Epoch: 6, loss: 0.45107316970825195, constraints: [[0.19874487]], dual: [0.42950717]\n",
      "Epoch: 7, loss: 0.44518139958381653, constraints: [[0.1968969]], dual: [0.39155674]\n",
      "Epoch: 8, loss: 0.4483039379119873, constraints: [[0.19979302]], dual: [0.4174498]\n",
      "Epoch: 9, loss: 0.4449792802333832, constraints: [[0.20392439]], dual: [0.4071264]\n",
      "Adding new rule: [\"SCHL_Bachelor's degree\"]\n",
      "Epoch: 10, loss: 0.4741983115673065, constraints: [[0.16101666]\n",
      " [0.23584912]], dual: [0.31487793 0.19219919]\n",
      "Epoch: 11, loss: 0.4621526598930359, constraints: [[0.19806134]\n",
      " [0.19731231]], dual: [0.11218626 0.26851994]\n",
      "Epoch: 12, loss: 0.4589827358722687, constraints: [[0.20331853]\n",
      " [0.19750932]], dual: [0.14878343 0.23960158]\n",
      "Epoch: 13, loss: 0.456064373254776, constraints: [[0.20340989]\n",
      " [0.20001102]], dual: [0.17203446 0.22350706]\n",
      "Epoch: 14, loss: 0.4528167247772217, constraints: [[0.19984417]\n",
      " [0.20018334]], dual: [0.17224553 0.22509651]\n",
      "Epoch: 15, loss: 0.452915757894516, constraints: [[0.20028786]\n",
      " [0.19798978]], dual: [0.17919251 0.21628089]\n",
      "Epoch: 16, loss: 0.45303717255592346, constraints: [[0.19767991]\n",
      " [0.19924784]], dual: [0.20215346 0.20341696]\n",
      "Epoch: 17, loss: 0.4488026201725006, constraints: [[0.19816925]\n",
      " [0.20107789]], dual: [0.17936422 0.21365072]\n",
      "Epoch: 18, loss: 0.4474322497844696, constraints: [[0.20243972]\n",
      " [0.19770829]], dual: [0.19363526 0.19924934]\n",
      "Epoch: 19, loss: 0.44523149728775024, constraints: [[0.19894241]\n",
      " [0.19986639]], dual: [0.18881151 0.20797709]\n",
      "Adding new rule: [\"SCHL_Bachelor's degree\"]\n",
      "Epoch: 21, loss: 0.444004625082016, constraints: [[0.20281071]\n",
      " [0.19906229]], dual: [0.1648008  0.21647066]\n",
      "Epoch: 22, loss: 0.4406166076660156, constraints: [[0.19563212]\n",
      " [0.20316195]], dual: [0.18020108 0.1995169 ]\n",
      "Epoch: 23, loss: 0.44051799178123474, constraints: [[0.19937512]\n",
      " [0.19904361]], dual: [0.17127064 0.20212421]\n",
      "Epoch: 24, loss: 0.43970397114753723, constraints: [[0.19608352]\n",
      " [0.20285781]], dual: [0.16641459 0.21068084]\n",
      "Epoch: 25, loss: 0.43785062432289124, constraints: [[0.20439962]\n",
      " [0.19974879]], dual: [0.17377089 0.20072384]\n",
      "Epoch: 26, loss: 0.4382886588573456, constraints: [[0.1997903 ]\n",
      " [0.19677506]], dual: [0.18875727 0.20327668]\n",
      "Epoch: 27, loss: 0.4347078800201416, constraints: [[0.19673462]\n",
      " [0.20092239]], dual: [0.18526758 0.20056012]\n",
      "Epoch: 28, loss: 0.4351325035095215, constraints: [[0.20338183]\n",
      " [0.19934723]], dual: [0.18159714 0.20501165]\n",
      "Epoch: 29, loss: 0.4318826496601105, constraints: [[0.20237946]\n",
      " [0.19871933]], dual: [0.16313595 0.2032165 ]\n",
      "Adding new rule: [\"SCHL_Master's degree\"]\n",
      "Epoch: 30, loss: 0.4895172715187073, constraints: [[0.18324081]\n",
      " [0.1386032 ]\n",
      " [0.23586092]], dual: [0.16052747 0.03312088 0.22963622]\n",
      "Epoch: 31, loss: 0.47621628642082214, constraints: [[0.19951342]\n",
      " [0.18914584]\n",
      " [0.19663899]], dual: [0.06264494 0.01115421 0.25164318]\n",
      "Epoch: 32, loss: 0.47473591566085815, constraints: [[0.20781302]\n",
      " [0.19781169]\n",
      " [0.19701752]], dual: [0.10785309 0.01591125 0.23135278]\n",
      "Epoch: 33, loss: 0.47206759452819824, constraints: [[0.19750466]\n",
      " [0.20085745]\n",
      " [0.19739281]], dual: [0.12129531 0.03747379 0.2020538 ]\n",
      "Epoch: 34, loss: 0.4709567129611969, constraints: [[0.19970586]\n",
      " [0.20193274]\n",
      " [0.19807454]], dual: [0.11643624 0.03946318 0.19718319]\n",
      "Epoch: 35, loss: 0.4664410352706909, constraints: [[0.20084562]\n",
      " [0.20224385]\n",
      " [0.19875218]], dual: [0.08343652 0.06886021 0.18490084]\n",
      "Epoch: 36, loss: 0.468825101852417, constraints: [[0.20645937]\n",
      " [0.19686051]\n",
      " [0.19910476]], dual: [0.14418125 0.05578113 0.17247406]\n",
      "Epoch: 37, loss: 0.4691556692123413, constraints: [[0.19619007]\n",
      " [0.20062655]\n",
      " [0.19826694]], dual: [0.14234646 0.05940946 0.17477702]\n",
      "Epoch: 38, loss: 0.4648185968399048, constraints: [[0.19782866]\n",
      " [0.20325247]\n",
      " [0.19822067]], dual: [0.11610236 0.0613581  0.18258895]\n",
      "Epoch: 39, loss: 0.46066346764564514, constraints: [[0.19726394]\n",
      " [0.20328804]\n",
      " [0.20069649]], dual: [0.07359716 0.0860594  0.17777123]\n",
      "Adding new rule: ['RAC1P_White alone']\n",
      "Epoch: 40, loss: 0.4608152210712433, constraints: [[0.20110293]\n",
      " [0.20017277]\n",
      " [0.19835765]\n",
      " [0.13206921]], dual: [0.04161525 0.09735359 0.16677514 0.00399639]\n",
      "Epoch: 41, loss: 0.4602111577987671, constraints: [[0.19947404]\n",
      " [0.19708476]\n",
      " [0.20141479]\n",
      " [0.12444633]], dual: [0.07056405 0.09274852 0.15693164 0.0043022 ]\n",
      "Epoch: 42, loss: 0.4601919651031494, constraints: [[0.20011171]\n",
      " [0.19991338]\n",
      " [0.19987684]\n",
      " [0.12141594]], dual: [0.0852823  0.07267334 0.16997497 0.00380093]\n",
      "Epoch: 43, loss: 0.4597286880016327, constraints: [[0.20356196]\n",
      " [0.20274365]\n",
      " [0.19560094]\n",
      " [0.11673688]], dual: [0.08048862 0.07909356 0.1618315  0.00375085]\n",
      "Epoch: 44, loss: 0.4590741693973541, constraints: [[0.20300386]\n",
      " [0.19909888]\n",
      " [0.20045251]\n",
      " [0.11921737]], dual: [0.11755036 0.07437026 0.16007693 0.0033522 ]\n",
      "Epoch: 45, loss: 0.45925086736679077, constraints: [[0.19634364]\n",
      " [0.19728414]\n",
      " [0.20183059]\n",
      " [0.11722523]], dual: [0.11517129 0.08441886 0.15404618 0.0039088 ]\n",
      "Epoch: 46, loss: 0.4584927260875702, constraints: [[0.20370135]\n",
      " [0.19755008]\n",
      " [0.19936593]\n",
      " [0.1158592 ]], dual: [0.11347151 0.08431723 0.15275715 0.00331574]\n",
      "Epoch: 47, loss: 0.45608630776405334, constraints: [[0.19928471]\n",
      " [0.20361618]\n",
      " [0.1998094 ]\n",
      " [0.12215839]], dual: [0.08876033 0.08223281 0.15654263 0.00386314]\n",
      "Epoch: 48, loss: 0.4578445553779602, constraints: [[0.20043739]\n",
      " [0.19783598]\n",
      " [0.20272855]\n",
      " [0.11964082]], dual: [0.11085627 0.07959111 0.15826902 0.0045353 ]\n",
      "Epoch: 49, loss: 0.4563068747520447, constraints: [[0.19564268]\n",
      " [0.19993015]\n",
      " [0.20124851]\n",
      " [0.11867826]], dual: [0.08272701 0.08996555 0.16049294 0.00508503]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.any(MSD_sample_y):\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m conj_indices = \u001b[43mget_conjuncts_MSD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMSD_sample_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMSD_sample_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mConjuncts_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAdding new rule: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_feat_msd.columns[conj_indices].to_list()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conj_indices \u001b[38;5;129;01min\u001b[39;00m constraints:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/humancompatible/humancompatible-train/src/humancompatible/detect/methods/msd/msd.py:46\u001b[39m, in \u001b[36mget_conjuncts_MSD\u001b[39m\u001b[34m(X_bin, y_bin, time_limit, n_min, solver)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03mRun the One-Rule MILP and return the indices of literals that form the\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03mMaximum-Subgroup-Discrepancy (MSD) rule.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m \u001b[33;03m        with an unexpected termination condition.\u001b[39;00m\n\u001b[32m     43\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     45\u001b[39m mio = OneRule()\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m indices, _ = \u001b[43mmio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_rule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_bin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_bin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_min\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m indices\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/humancompatible/humancompatible-train/src/humancompatible/detect/methods/msd/one_rule.py:275\u001b[39m, in \u001b[36mOneRule.find_rule\u001b[39m\u001b[34m(self, X, y, verbose, n_min, time_limit, solver_name)\u001b[39m\n\u001b[32m    270\u001b[39m     logger.warning(\n\u001b[32m    271\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTime limit not set! Not implemented for the selected solver \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolver_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    272\u001b[39m     )\n\u001b[32m    274\u001b[39m \u001b[38;5;66;03m# Solve the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m result = \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mint_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_solutions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtee\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m is_optimal = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.solver.termination_condition != pyo.TerminationCondition.optimal:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detect-train/lib/python3.11/site-packages/pyomo/opt/base/solvers.py:636\u001b[39m, in \u001b[36mOptSolver.solve\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    634\u001b[39m     \u001b[38;5;28mself\u001b[39m._initialize_callbacks(_model)\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m _status = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_transformation_data\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transformation_data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detect-train/lib/python3.11/site-packages/pyomo/opt/solver/shellcmd.py:266\u001b[39m, in \u001b[36mSystemCallSolver._apply_solver\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    263\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSolver problem files: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m._problem_files))\n\u001b[32m    265\u001b[39m sys.stdout.flush()\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m \u001b[38;5;28mself\u001b[39m._rc, \u001b[38;5;28mself\u001b[39m._log = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_command\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m sys.stdout.flush()\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Bunch(rc=\u001b[38;5;28mself\u001b[39m._rc, log=\u001b[38;5;28mself\u001b[39m._log)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detect-train/lib/python3.11/site-packages/pyomo/opt/solver/shellcmd.py:334\u001b[39m, in \u001b[36mSystemCallSolver._execute_command\u001b[39m\u001b[34m(self, command)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m TeeStream(*ostreams) \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m         results = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m            \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSTDERR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m            \u001b[49m\u001b[43muniversal_newlines\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcwd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m         t.STDOUT.flush()\n\u001b[32m    345\u001b[39m         t.STDERR.flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detect-train/lib/python3.11/subprocess.py:550\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    552\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detect-train/lib/python3.11/subprocess.py:1201\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1199\u001b[39m         stderr = \u001b[38;5;28mself\u001b[39m.stderr.read()\n\u001b[32m   1200\u001b[39m         \u001b[38;5;28mself\u001b[39m.stderr.close()\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1203\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detect-train/lib/python3.11/subprocess.py:1264\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m     endtime = _time() + timeout\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detect-train/lib/python3.11/subprocess.py:2053\u001b[39m, in \u001b[36mPopen._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   2051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2052\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2053\u001b[39m (pid, sts) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2054\u001b[39m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[32m   2055\u001b[39m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[32m   2056\u001b[39m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[32m   2057\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pid == \u001b[38;5;28mself\u001b[39m.pid:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detect-train/lib/python3.11/subprocess.py:2011\u001b[39m, in \u001b[36mPopen._try_wait\u001b[39m\u001b[34m(self, wait_flags)\u001b[39m\n\u001b[32m   2009\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[32m   2010\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2011\u001b[39m     (pid, sts) = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2012\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[32m   2013\u001b[39m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[32m   2014\u001b[39m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[32m   2015\u001b[39m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[32m   2016\u001b[39m     pid = \u001b[38;5;28mself\u001b[39m.pid\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from humancompatible.detect import detect_and_score\n",
    "from humancompatible.detect.helpers import report_subgroup_bias\n",
    "from humancompatible.detect.methods.msd import get_conjuncts_MSD\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "constraints = []\n",
    "\n",
    "\n",
    "# TODO: train until val learning rate plateaus\n",
    "# TODO: automatically relax constraints if too harsh?\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # clear epoch stats\n",
    "    loss_log = []\n",
    "    c_log = []\n",
    "    duals_log = []\n",
    "    if (epoch % msd_interval == 0 and len(constraints) <= 5):\n",
    "            ### find new MSD ###\n",
    "            with torch.inference_mode():\n",
    "                indices = random.sample(range(len(df_feat_msd)), MSD_kwargs[\"n_samples\"])\n",
    "                MSD_sample_model_input = dataset[indices][0]\n",
    "                MSD_sample_x = df_feat_msd.iloc[indices].to_numpy(dtype=bool)\n",
    "                # get binary predictions on sample\n",
    "                # TODO: replace this with e.g. indicator of a true positive or whatever\n",
    "                MSD_sample_y = (\n",
    "                    torch.nn.functional.sigmoid(model_con(MSD_sample_model_input)).squeeze()\n",
    "                    > 0.5\n",
    "                ).numpy()\n",
    "            \n",
    "            if not np.any(MSD_sample_y):\n",
    "                continue\n",
    "\n",
    "            conj_indices = get_conjuncts_MSD(MSD_sample_x, MSD_sample_y, **Conjuncts_kwargs)\n",
    "            print(f\"Adding new rule: {df_feat_msd.columns[conj_indices].to_list()}\")\n",
    "            if conj_indices in constraints:\n",
    "                continue\n",
    "            \n",
    "            constraints.append(conj_indices)\n",
    "            if epoch > 0:\n",
    "                dual.add_constraint_group(m=1)\n",
    "\n",
    "\n",
    "    for batch_input, batch_sens, batch_label in dataloader:# tqdm(dataloader, leave=False):\n",
    "        # calculate constraints and constraint grads\n",
    "        out = model_con(batch_input)\n",
    "        c_log.append([])\n",
    "        batch_cons = []\n",
    "        for j, conj_indices in enumerate(constraints):\n",
    "            # one-hot evaluation of rule `j`\n",
    "            sens_attrs = batch_sens[:, conj_indices]\n",
    "            rule_eval = torch.prod(sens_attrs, dim=1, keepdim=True, dtype=bool)\n",
    "            batch_rule_groups = torch.cat([rule_eval, ~rule_eval], dim=1)\n",
    "            # evaluate fairret loss\n",
    "            fair_loss = fair_criterion(out, batch_rule_groups)\n",
    "            batch_cons.append(fair_loss.unsqueeze(0))\n",
    "            c_log[-1].append([fair_loss.detach().item()])\n",
    "\n",
    "        batch_cons = torch.cat(batch_cons) - fair_crit_bound + slack_vars[:len(batch_cons)]\n",
    "\n",
    "        # primal eval and update\n",
    "        loss = criterion(out, batch_label)\n",
    "        lagrangian = dual.forward_update(loss, batch_cons)\n",
    "        lagrangian.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_log.append(loss.detach().numpy())\n",
    "        duals_log.append(dual.duals.detach().numpy())\n",
    "        \n",
    "        # slack variables must be non-negative. this is the \"projection\" step from the SSL-ALM paper\n",
    "        with torch.no_grad():\n",
    "            for s in slack_vars:\n",
    "                if s < 0:\n",
    "                    s.zero_()\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch}, \"\n",
    "        f\"loss: {np.mean(loss_log[:-100])}, \"\n",
    "        f\"constraints: {np.mean(c_log[:-100], axis=0)}, \"\n",
    "        f\"dual: {np.mean(duals_log[:-100], axis=0)}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed41e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sens[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from humancompatible.detect.binarizer import Bin\n",
    "\n",
    "\n",
    "def rule_to_indicator(rule, features):\n",
    "    \"\"\"\n",
    "    Given a rule and a tensor of one-hot variables, creates a new indicator column denoting the rule.\n",
    "    `features`must have shape (`batch_size`,`n_features`)\n",
    "    \"\"\"\n",
    "    for feature_idx, bin in rule:\n",
    "        features[feature_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579678d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    f = model_con.forward(dataset[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de6e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6255, dtype=torch.float16)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(((torch.nn.functional.sigmoid(f) > 0.5) == dataset[:][2]).to(torch.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993899e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4769, 0.4559, 0.4392, 0.4757, 0.4919, 0.5193, 0.4537, 0.4199, 0.4385,\n",
       "        0.4023, 0.3916, 0.4016, 0.4039, 0.4031, 0.4086, 0.4025, 0.4282, 0.4300,\n",
       "        0.4723, 0.5128, 0.4259, 0.4359, 0.5164, 0.4432, 0.4597, 0.4572, 0.4796,\n",
       "        0.5135, 0.4557, 0.4454, 0.4731, 0.4720, 0.4660, 0.4348, 0.4614, 0.4749],\n",
       "       dtype=torch.float64, grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairret.statistic import PositiveRate\n",
    "\n",
    "preds = torch.nn.functional.sigmoid(model_con(features_train))\n",
    "pr = PositiveRate()\n",
    "pr(preds, sens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac5a57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4357, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair_criterion(model_con(features_train), sens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d5dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "window_len = 5\n",
    "c_mavg = np.array(\n",
    "    [np.mean(ep_c_log[i : i + window_len]) for i in range(0, len(ep_c_log), window_len)]\n",
    ")\n",
    "plt.plot(np.array(c_mavg).flatten(), lw=0.05)\n",
    "plt.hlines(y=fair_crit_bound, xmin=0, xmax=len(c_mavg), colors=\"black\", ls=\"--\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detect-train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
